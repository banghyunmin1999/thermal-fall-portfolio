# 🔥 실시간 열화상 기반 낙상 감지 시스템

> NVIDIA Jetson, TensorRT, PyCUDA를 활용해 엣지 환경에서 초고속 추론에 최적화된 실시간 열화상 기반 낙상 및 위험 상황 감지 시스템입니다.

-----

### 📄 목차

- [🧠 프로젝트 개요](#-프로젝트-개요)
- [🎯 개발 동기](#-개발-동기)
- [🏗️ 시스템 아키텍처](#️-시스템-아키텍처)
- [📦 기술 스택](#-기술-스택)
- [📌 모델 개발 및 최적화](#-모델-개발-및-최적화)
- [📈 성능 및 결과](#-성능-및-결과)
- [👥 Contributors](#-contributors)
- [🙂 나의 기여](#-나의-기여)


-----

### 🧠 프로젝트 개요

본 프로젝트는 **열화상 카메라**로부터 **RTSP**를 통해 실시간 영상을 수신하고, 파인튜닝된 **YOLOv11n 모델**을 사용하여 낙상 등 위험 상황을 감지한 뒤 웹 인터페이스에 결과를 출력하는 시스템을 구현합니다.

실시간 처리에 필수적인 빠른 추론 속도를 엣지 디바이스(NVIDIA Jetson)에서 달성하기 위해 **TensorRT**, **PyCUDA**, **GStreamer** 기반의 병렬 처리 파이프라인을 적용하여 시스템을 최적화했습니다. 최종 결과물은 바운딩 박스가 표시된 라이브 비디오 스트림과 실시간 알림 시스템을 포함합니다.

-----

### 🎯 개발 동기

이 프로젝트는 공공장소의 안전을 강화하기 위한 프라이버시 보호 모니터링 솔루션의 필요성에서 출발했습니다.

  * **프라이버시 문제**: 화장실과 같이 민감한 장소에서는 사생활 침해 우려로 CCTV 설치가 제한됩니다. 열화상 카메라는 열 정보만 감지하므로 익명성을 보장할 수 있습니다.
  * **안전사고 예방**: 지하철 내 취객 등 위험에 노출된 사람들의 안전사고를 신속하게 감지할 필요성이 커지고 있습니다. 2024년 1분기에만 서울교통공사에 2,500건 이상의 취객 관련 민원이 접수되었습니다.
  * **수동 모니터링의 한계**: 역무원이 성별에 따라 특정 구역(예: 여성 화장실)에 즉시 진입하기 어려워 비상 상황 발생 시 대응이 늦어질 수 있습니다.
  * **선제적 대응**: 실시간 감지 시스템은 즉각적인 알림을 통해 더 빠른 초기 대응을 가능하게 하여 사고를 예방합니다.

-----

### 🏗️ 시스템 아키텍처

시스템은 처리량을 극대화하기 위해 영상 입력부터 최종 추론 결과 출력까지 모든 과정을 다중 스레드 파이프라인으로 설계했습니다.

#### Part 1: 전체 시스템 흐름

애플리케이션은 AI 분석을 관리하고 프론트엔드를 제공하는 Flask 웹 서버를 중심으로 구축됩니다.

1.  **사용자 접속**: 사용자가 웹 브라우저를 통해 Flask 웹 서버에 접속합니다.
2.  **비디오 스트림**: 브라우저가 `/video_feed` 엔드포인트를 요청합니다. 서버는 별도 스레드에서 AI 분석을 수행하는 `VideoCamera` 객체를 통해 multipart/x-mixed-replace 형식의 JPEG 스트림을 실시간으로 전송합니다.
3.  **상태 업데이트**: 동시에 브라우저는 `/status_feed` 엔드포인트와 **SSE(Server-Sent Events)** 연결을 수립하여, 1초마다 감지 현황과 알림 메시지가 담긴 JSON 데이터를 수신합니다.

#### Part 2: 실시간 알림 로직

시스템은 오탐이나 알림 깜빡임을 방지하기 위해 타임-윈도우 기반의 알림 로직을 사용합니다.

1.  **탐지 기록 추적**: 최근 10초 동안 처리된 모든 프레임에서 가장 위험도가 높은 탐지 결과(Warning \> Caution \> Normal 순)를 기록합니다.
2.  **알림 조건 계산**: 10초 윈도우 내에서 'Warning'과 'Caution' 상태의 프레임 비율을 계산합니다.
3.  **상태 관리**: '비정상' 프레임의 비율이 설정된 임계값(예: 70%)을 초과하면 알림을 발생시킵니다. 반복적인 알림을 방지하기 위해 한 번 알림이 발생하면 일정 시간(예: 30초)의 쿨다운을 적용합니다.

-----

### 📦 기술 스택

본 프로젝트는 NVIDIA 엣지 컴퓨팅 플랫폼에서 AI 개발을 위한 최신 기술 스택을 활용합니다.

| 구분 | 기술/버전 | 설명 |
| --- | --- | --- |
| **하드웨어** | NVIDIA JETSON ORIN NANO  | 엣지 AI 추론을 위한 개발자 키트입니다. |
| **카메라** | TD160-B90 열화상 카메라  | RTSP를 통해 실시간 열화상 비디오 피드를 제공합니다. |
| **운영체제** | Ubuntu 22.04 (ARM64)  | Jetson 장치에서 사용하는 운영체제입니다. |
| **NVIDIA SDK** | JetPack 6.2  | AI 애플리케이션 개발을 위한 NVIDIA의 통합 SDK입니다. |
| **GPU 가속** | CUDA 12.6.11, cuDNN 9.10.11  | 병렬 컴퓨팅 플랫폼과 딥러닝 연산 가속 라이브러리입니다. |
| **추론 엔진** | TensorRT  | 고성능 딥러닝 추론 옵티마이저 및 런타임입니다. |
| **딥러닝**| PyTorch 2.7.0, torchvision 0.22.0  | 모델 학습을 위한 핵심 프레임워크와 컴퓨터 비전 라이브러리입니다. |
| **영상 처리** | OpenCV (GStreamer & CUDA 지원)  | 실시간 컴퓨터 비전을 위한 라이브러리로, GStreamer와 CUDA 가속을 지원하도록 직접 빌드했습니다. |
| **RTSP 수신** | GStreamer  | 파이프라인 기반의 멀티미디어 프레임워크로, UDP를 통해 RTSP 스트림을 효율적으로 수신합니다. |
| **병렬 처리** | Python Threading + Queue  | 캡처, 전처리, 추론, 후처리 단계를 병렬로 관리하여 FPS를 향상시킵니다. |
| **웹 프레임워크**| Flask | 웹 애플리케이션 및 API를 구축하기 위한 마이크로 웹 프레임워크입니다. |

-----

### 📌 모델 개발 및 최적화

실시간 성능을 달성하기 위해 데이터 준비, 모델 파인튜닝, 광범위한 최적화 과정을 거쳤습니다.

#### 1\. 데이터 수집 및 준비

  * **비디오 데이터**: 여성 8명, 남성 9명, 총 17명의 참가자를 대상으로 시뮬레이션 환경에서 영상을 촬영했습니다.
  * **프레임 추출**: 30 FPS 영상을 초당 3프레임으로 샘플링하여 320x240 해상도의 원본 이미지 3,095장을 추출했습니다.
  * **데이터 라벨링**: **Roboflow**를 사용하여 `normal`, `caution`, `warning` 세 개의 클래스로 바운딩 박스 라벨링을 진행했습니다.
  * **데이터 증강**: 모델의 일반화 성능을 높이기 위해 훈련 데이터셋을 수평 뒤집기, 약간의 회전, 밝기 조절, 블러, 노이즈 추가 등의 기법으로 3배 증강하여 총 7,423개의 데이터셋을 구축했습니다.

#### 2\. 모델 파인튜닝

  * **베이스 모델**: COCO 데이터셋으로 사전 학습된 **YOLOv11n** 모델을 기반으로 사용했습니다.
  * **학습**: 100 에포크, 배치 사이즈 16, 입력 이미지 크기 320x320으로 모델을 파인튜닝했습니다. 과적합을 방지하기 위해 20 에포크 동안 성능 개선이 없으면 학습을 조기 종료하는 Early Stopping을 적용했습니다.

#### 3\. 성능 최적화

  * **모델 변환**: 파인튜닝된 PyTorch 모델(`.pt`)을 `.onnx` 포맷을 거쳐 고도로 최적화된 \*\*TensorRT 엔진(`.engine`)\*\*으로 변환했습니다. 이 과정은 추론 속도를 극적으로 향상시킵니다.
  * **혼합 정밀도 추론**: TensorRT 엔진을 **INT8 + FP16**의 혼합 정밀도로 빌드하여 정확도 손실을 최소화하면서 최대 속도를 달성했습니다.
  * **병렬 처리 파이프라인**: 초기 순차 처리(캡처 → 전처리 → 추론 → 후처리) 방식은 **7.64 FPS**의 성능을 보였습니다. 이를 큐(Queue)로 관리되는 4개의 병렬 스레드 구조로 재설계하여 처리량을 **11.31 FPS**로 약 50% 가까이 향상시켰습니다.
  * **Letterbox 전처리**: 모델이 요구하는 320x320 입력에 320x240 이미지를 단순히 리사이징하는 대신, 원본 비율을 유지하며 회색 패딩을 추가하는 **Letterbox** 기법을 사용했습니다. 이는 객체 왜곡을 방지하여 실시간 추론 정확도를 높이는 데 결정적인 역할을 했습니다.

-----

### 📈 성능 및 결과

다양한 모델과 전처리 기법을 비교하기 위해 광범위한 테스트를 수행했습니다.

  * **핵심 결론**: 실시간 추론 성능은 학습 단계와 배포 단계의 전처리 방식 일관성에 크게 좌우됩니다.

  * **모델 V2 vs. V3 비교**:

      * **V2 모델**: 320x240 이미지를 320x320으로 강제 리사이징하여 학습했습니다. 이 모델은 동일하게 왜곡된 검증 데이터셋에서는 높은 평가지표를 보였지만, Letterbox를 사용하는 실제 라이브 환경에서는 성능이 저하되었습니다.
      * **V3 모델**: 라이브 추론 파이프라인과 동일한 Letterbox 전처리 방식을 사용해 학습했습니다. 초기 검증 단계의 평가지표는 V2보다 약간 낮았지만, 실제 애플리케이션 환경에서는 훨씬 더 높고 안정적인 정확도를 보였습니다. **최종적으로 V3가 최적 모델로 선정되었습니다**.

  * **최적화 효과**: 다중 스레드 파이프라인을 적용하여 프레임 처리 속도를 **7.64 FPS**에서 **11.31 FPS**로 끌어올렸으며, 이는 부드러운 실시간 시스템 구현에 필수적인 성능 향상이었습니다.

-----

-----

### 👥 Contributors

**Hyunmin Bang (방현민)**  
📧 연락처: banghyunmin1999@gmail.com  
🔗 GitHub: [https://github.com/banghyunmin1999](https://github.com/banghyunmin1999)  
🔗 LinkedIn: [www.linkedin.com/in/hyunmin-bang-6b944936b](https://www.linkedin.com/in/hyunmin-bang-6b944936b)  
🤗 Hugging Face: [https://huggingface.co/banghyunmin](https://huggingface.co/banghyunmin)

---

**Eunji Choi (최은지)**  
📧 연락처: creweunji@gmail.com  
🔗 GitHub: [https://github.com/Eunji-Choi-Lulu](https://github.com/Eunji-Choi-Lulu)  
🔗 LinkedIn: [https://www.linkedin.com/in/eunji-choi-b3bbb788](https://www.linkedin.com/in/eunji-choi-b3bbb788)  
🤗 Hugging Face: [https://huggingface.co/EunjiChoi] (https://huggingface.co/EunjiChoi)

-----

-----

## 🙂 나의 기여

본 프로젝트의 **전 과정에 주도적으로 참여**하여 기획부터 최종 구현까지 핵심적인 역할을 수행했습니다.

### 1\. 프로젝트 기획 및 시스템 설계

  * 프로젝트 목표 및 요구사항을 정의하고, 개인정보 보호라는 제약 조건 하에서 문제를 해결할 수 있는 열화상 기반 솔루션을 제안했습니다.
  * RTSP 스트리밍, 실시간 추론, 웹 시각화로 이어지는 **전체 시스템 아키텍처를 설계**했으며, 특히 성능 최적화를 위한 **다중 스레드 병렬 처리 파이프라인을 직접 구상하고 도입**했습니다.

### 2\. 개발 환경 구축 및 하드웨어 연동

  * **NVIDIA Jetson Orin Nano**에 Ubuntu, JetPack, CUDA, cuDNN, TensorRT 등 AI 개발 환경 전체를 구축하고 안정화했습니다.
  * 열화상 카메라의 **RTSP 스트림을 GStreamer 파이프라인을 통해 수신**하고, **CUDA 가속을 지원하는 OpenCV를 소스에서 직접 빌드**하여 시스템에 통합하는 작업을 주도했습니다.

### 3\. 데이터 파이프라인 구축 및 모델 개발

  * 실험 환경에서 직접 데이터를 수집하고, 초당 프레임 추출 스크립트를 작성하여 **초기 데이터셋을 구축**했습니다.
  * **Roboflow**를 활용한 데이터 라벨링 및 증강 전략을 수립하여 모델의 일반화 성능을 극대화했습니다.
  * **YOLOv11n 모델의 파인튜닝**을 직접 수행했으며, 강제 리사이징(V2)과 Letterbox(V3) 등 다양한 전처리 방식이 모델 성능에 미치는 영향을 실험하고 분석하여 **최적의 학습 파이프라인(V3)을 최종 확정**했습니다.

### 4\. 핵심 성능 최적화

  * 추론 속도를 극대화하기 위해 학습된 PyTorch 모델을 **ONNX를 거쳐 TensorRT 엔진으로 변환**하는 전 과정을 책임졌습니다.
  * 양자화(Quantization)를 통해 **INT8 및 FP16 혼합 정밀도 추론**을 구현하여 속도와 정확도의 균형점을 찾는 작업을 주도했습니다.
  * 순차 처리로 인해 발생했던 병목 현상을 분석하고, **Python의 Threading과 Queue를 이용한 병렬 처리 구조를 도입**하여 **FPS를 50% 가까이 향상**시키는 핵심적인 성능 개선을 이뤄냈습니다.

### 5\. 애플리케이션 개발 및 문제 해결

  * **Flask**를 사용하여 백엔드 서버를 구축하고, 실시간 영상 스트리밍(multipart JPEG)과 상태 알림(SSE) 기능을 구현했습니다.
  * 개발 전 과정에서 발생하는 **라이브러리 의존성, 버전 충돌, 하드웨어 호환성 등 다양한 문제를 해결**하며 프로젝트를 안정적으로 이끌었습니다.
